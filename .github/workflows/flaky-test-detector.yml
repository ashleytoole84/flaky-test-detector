name: Flaky Test Detector

on:
  workflow_call:
    inputs:
      repository:
        description: 'Repository to analyze (e.g., <org-name>/platform-engineer-tech-case-49378219)'
        required: true
        type: string
      workflow-name:
        description: 'Name of the workflow to analyze (e.g., CI)'
        required: true
        type: string
      runs-limit:
        description: 'Number of previous runs to analyze'
        default: 10
        type: number
      branch:
        description: 'Branch to filter runs (e.g., main)'
        default: 'main'
        type: string
    secrets:
      github-token:
        description: 'GitHub PAT with repo and workflow scopes'
        required: true
    outputs:
      flaky-tests:
        description: 'JSON string of flaky tests and their failure counts'
        value: ${{ jobs.detect-flaky-tests.outputs.flaky-tests }}

jobs:
  detect-flaky-tests:
    runs-on: ubuntu-latest
    outputs:
      flaky-tests: ${{ steps.process-results.outputs.flaky-tests }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install requests

      - name: Fetch previous workflow runs
        id: fetch-runs
        env:
          GITHUB_TOKEN: ${{ secrets.github-token }}
          REPO: ${{ inputs.repository }}
          WORKFLOW_NAME: ${{ inputs.workflow-name }}
          RUNS_LIMIT: ${{ inputs.runs-limit }}
          BRANCH: ${{ inputs.branch }}
        run: |
          python - <<EOF
          import requests
          import json

          headers = {"Authorization": f"Bearer $GITHUB_TOKEN", "Accept": "application/vnd.github.v3+json"}
          url = f"https://api.github.com/repos/$REPO/actions/runs?per_page=$RUNS_LIMIT&branch=$BRANCH"
          response = requests.get(url, headers=headers)
          response.raise_for_status()
          runs = response.json()["workflow_runs"]

          # Filter runs by workflow name
          runs = [run for run in runs if run["name"] == "$WORKFLOW_NAME"]
          run_ids = [run["id"] for run in runs]

          print(f"Found {len(run_ids)} runs for workflow '$WORKFLOW_NAME'")
          with open("run_ids.txt", "w") as f:
              json.dump(run_ids, f)
          EOF

      - name: Fetch test results from runs
        id: fetch-results
        env:
          GITHUB_TOKEN: ${{ secrets.github-token }}
          REPO: ${{ inputs.repository }}
        run: |
          python - <<EOF
          import requests
          import json
          import re

          headers = {"Authorization": f"Bearer $GITHUB_TOKEN", "Accept": "application/vnd.github.v3+json"}
          with open("run_ids.txt") as f:
              run_ids = json.load(f)

          test_results = {}
          for run_id in run_ids:
              # Fetch job logs
              url = f"https://api.github.com/repos/$REPO/actions/runs/{run_id}/jobs"
              response = requests.get(url, headers=headers)
              response.raise_for_status()
              jobs = response.json()["jobs"]

              for job in jobs:
                  logs_url = job["logs_url"]
                  if logs_url:
                      log_response = requests.get(logs_url, headers=headers)
                      log_response.raise_for_status()
                      logs = log_response.text
                      # Parse logs for test failures (adjust regex for your test framework)
                      for line in logs.splitlines():
                          match = re.search(r'^.*✕.*\((.*)\)', line)  # Example for Jest
                          if match:
                              test_name = match.group(1).strip()
                              test_results.setdefault(test_name, {"pass": 0, "fail": 0})["fail"] += 1
                          elif re.search(r'^.*✓.*\((.*)\)', line):  # Example for Jest pass
                              test_name = match.group(1).strip()
                              test_results.setdefault(test_name, {"pass": 0, "fail": 0})["pass"] += 1

          # Identify flaky tests (failed and passed in different runs)
          flaky_tests = {k: v["fail"] for k, v in test_results.items() if v["pass"] > 0 and v["fail"] > 0}
          with open("flaky-tests.json", "w") as f:
              json.dump(flaky_tests, f)
          print(f"Flaky tests: {json.dumps(flaky_tests)}")
          print(f"flaky-tests={json.dumps(flaky_tests)}", file=open("$GITHUB_OUTPUT", "a"))
          EOF

      - name: Summarize results
        id: summarize
        run: |
          echo "Flaky Test Summary:"
          jq -r 'to_entries | .[] | "- \(.key): failed \(.value) out of ${{ inputs.runs-limit }} runs"' flaky-tests.json > flaky-tests-summary.txt
          cat flaky-tests-summary.txt
        env:
          FLAKY_TESTS: ${{ steps.fetch-results.outputs.flaky-tests }}

      - name: Upload flaky test summary
        uses: actions/upload-artifact@v4
        with:
          name: flaky-tests-summary
          path: flaky-tests-summary.txt